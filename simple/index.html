<head>
    <title>Long Peng</title>
    <meta name="author" content="Long Peng">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta property="og:title" content="Long Peng">
    <meta property="og:description" content="PhD student, USTC">
    <meta property="og:image" content="/simple/assets/avatar.jpg">
    <meta property="og:url" content="https://peylnog.github.io/simple/">
    <meta name="twitter:card" content="summary_large_image">
    <link rel="stylesheet" href="css/style.css">
</head>

<div class="header noselect" id="about">
    <div class="content row">
        <div class="header-profile-picture"></div>
        <div class="header-text">
            <div class="header-name">
                <h1>Long Peng</h1>
            </div>
            <div class="header-subtitle">
                PhD student, University of Science and Technology of China
            </div>
            <div class="header-links">
                <a class="btn" href="#contact">Email</a> /
                <a class="btn" href="https://scholar.google.com/citations?user=nRPD3tAAAAAJ">Google Scholar</a> /
                <a class="btn" href="https://github.com/peylnog">GitHub</a>
            </div>
            <div>
                <p>
                    Long Peng (ÂΩ≠Èæô) is a PhD student at <a href="https://www.ustc.edu.cn/">University of Science and Technology of China (USTC)</a>. 
                    His research interests include computer vision, especially focusing on image/video enhancement and generation.
                </p>
            </div>
        </div>
    </div>
</div>

<div class="content" style="padding-bottom: 64px;">
    <!-- News -->
    <div id="news">
        <h2 class="noselect">News</h2>
        <div class="news-container">
            <ul class="news-list noselect">
                <li class="news-item">2026/01 -- <span style="color: #f09228;">üéâ Google Scholar Citations exceeded 1000+!</span></li>
                <li class="news-item">2026/01 -- One paper (ContinuousSR) got accepted by <span class="bold">ICLR 2026</span>! <span style="color: #f09228;">üî• 500+ GitHub Stars</span></li>
                <li class="news-item">2025/05 -- One paper (PMQ-VE) got accepted by <span class="bold">NeurIPS 2025</span>!</li>
                <li class="news-item">2025/02 -- One paper (QMambaBSR) got accepted by <span class="bold">CVPR 2025</span>.</li>
                <li class="news-item">2025/01 -- One paper (TAMambaIR) got accepted by <span class="bold">IJCAI 2025</span> as <span class="bold">Oral</span>.</li>
                <li class="news-item">2024/12 -- One paper got accepted by <span class="bold">AAAI 2025</span>.</li>
                <li class="news-item">2024/09 -- One paper (Ultrapixel) got accepted by <span class="bold">NeurIPS 2024</span>.</li>
                <li class="news-item">2024/09 -- One paper got accepted by <span class="bold">ICLR 2025</span>.</li>
            </ul>
        </div>
    </div>

    <!-- Publications -->
    <div id="publications">
        <h2 class="noselect">Publications</h2>
        <p>* Equal contribution. </p>

        <!-- ========== Published Papers ========== -->
        <h3 style="margin-top: 24px; margin-bottom: 16px; color: #345; border-bottom: 1px solid #ddd; padding-bottom: 8px;">Published Papers</h3>

        <!-- ICLR 2026: ContinuousSR -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/continuousSR.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">Pixel to Gaussian: Ultra-Fast Continuous Super-Resolution with 2D Gaussian Modeling</a>
                <span class="stars">‚≠ê 500+</span><br/>
                <span class="bold">Long Peng*</span>, Anran Wu*, Wenbo Li, Peizhe Xia, Xueyuan Dai, Xinjie Zhang, Xin Di, Haoze Sun, Renjing Pei, Yang Wang, Yang Cao, Zheng-Jun Zha. <span style="color: #666; font-size: 11px;">Co-first Author</span><br/>
                <span class="italic">ICLR</span>, 2026 <br/>
                <a class="btn btn-dark" href="https://peylnog.github.io/ContinuousSR_web">project</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2503.06617">paper</a> / <a class="btn btn-dark" href="https://github.com/peylnog/ContinuousSR">code</a>
            </div>
        </div>

        <!-- NeurIPS 2025: PMQ-VE -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/PMQ-VE.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">PMQ-VE: Progressive Multi-Frame Quantization for Video Enhancement</a><br/>
                ZhanFeng Feng*, <span class="bold">Long Peng*</span>, Xin Di*, Yong Guo, Wenbo Li, Yulun Zhang, Renjing Pei, Yang Wang, Yang Cao, Zheng-Jun Zha. <span style="color: #666; font-size: 11px;">Project Leader, Co-first Author</span><br/>
                <span class="italic">NeurIPS</span>, 2025 <br/>
                <a class="btn btn-red" href="https://arxiv.org/pdf/2505.12266">paper</a> / <a class="btn btn-dark" href="https://github.com/xiaoBIGfeng/PMQ-VE">code</a>
            </div>
        </div>

        <!-- CVPR 2025: QMambaBSR -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/QMambaBSR.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">QMambaBSR: Burst Image Super-Resolution with Query State Space Model</a><br/>
                Xin Di*, <span class="bold">Long Peng*</span>, Peizhe Xia, Wenbo Li, Renjing Pei, Yang Cao, Yang Wang, Zheng-Jun Zha. <span style="color: #666; font-size: 11px;">Project Leader, Co-first Author</span><br/>
                <span class="italic">CVPR</span>, 2025 <br/>
                <a class="btn btn-red" href="https://arxiv.org/abs/2408.08665">paper</a>
            </div>
        </div>

        <!-- IJCAI 2025 Oral: TAMambaIR -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/TAMambaIR.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">Directing Mamba to Complex Textures: An Efficient Texture-Aware State Space Model for Image Restoration</a><br/>
                <span class="bold">Long Peng*</span>, Xin Di*, Zhanfeng Feng, Wenbo Li, Renjing Pei, Yang Wang, Xueyang Fu, Yang Cao, Zheng-Jun Zha. <span style="color: #666; font-size: 11px;">Co-first Author</span><br/>
                <span class="italic">IJCAI</span>, 2025 (<span style="color: #f09228;">Oral</span>) <br/>
                <a class="btn btn-red" href="https://arxiv.org/pdf/2501.16583">paper</a>
            </div>
        </div>

        <!-- ICLR 2025 -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/ICLR2025.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">Towards Realistic Data Generation for Real-World Super-Resolution</a><br/>
                <span class="bold">Long Peng</span>, Wenbo Li, Renjing Pei, Jingjing Ren, Jiaqi Xu, Yang Wang, Yang Cao, Zheng-Jun Zha.<br/>
                <span class="italic">ICLR</span>, 2025 <br/>
                <a class="btn btn-red" href="https://arxiv.org/abs/2406.07255">paper</a>
            </div>
        </div>

        <!-- AAAI 2025 -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/AAAI2025.png); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">Boosting Image De-raining Via Central-Surrounding Synergistic Convolution</a><br/>
                <span class="bold">Long Peng</span>, Yang Wang, Xin Di, Peizhe Xia, Xueyang Fu, Yang Cao, Zheng-Jun Zha.<br/>
                <span class="italic">AAAI</span>, 2025 <br/>
            </div>
        </div>

        <!-- NeurIPS 2024: Ultrapixel -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/NIPS2024.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">Ultrapixel: Advancing ultra-high-resolution image synthesis to new peaks</a><br/>
                Jingjing Ren, Wenbo Li, Haoyu Chen, Renjing Pei, Bin Shao, Yong Guo, <span class="bold">Long Peng</span>, Fenglong Song, Lei Zhu.<br/>
                <span class="italic">NeurIPS</span>, 2024 <br/>
                <a class="btn btn-red" href="https://arxiv.org/abs/2407.02158">paper</a>
            </div>
        </div>

        <!-- TMM 2024 -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/TMM2024.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">Lightweight Adaptive Feature De-drifting for Compressed Image Classification</a><br/>
                <span class="bold">Long Peng</span>, Yang Cao, Yuejin Sun, Yang Wang.<br/>
                <span class="italic">IEEE Transactions on Multimedia (TMM)</span>, 2024 <br/>
                <a class="btn btn-red" href="https://ieeexplore.ieee.org/abstract/document/10400436/">paper</a> / <a class="btn btn-dark" href="https://github.com/peylnog/FDNet">code</a>
            </div>
        </div>

        <!-- TAI 2023 -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/TAI.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">Brightness Perceiving for Recursive Low-Light Image Enhancement</a><br/>
                Haodian Wang*, <span class="bold">Long Peng*</span>, Yuejin Sun, Zengyu Wan, Yang Wang, Yang Cao. <span style="color: #666; font-size: 11px;">Co-first Author</span><br/>
                <span class="italic">IEEE Transactions on Artificial Intelligence (TAI)</span>, 2023 <br/>
                <a class="btn btn-red" href="https://ieeexplore.ieee.org/abstract/document/10341542">paper</a>
            </div>
        </div>

        <!-- SPIC 2021 -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/SPIC.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">Ensemble Image Deraining Network via Progressive Structural Boosting Constraints</a><br/>
                <span class="bold">Long Peng</span>, Aiwen Jiang, Haoran Wei, Bo Liu, Mingwen Wang.<br/>
                <span class="italic">Signal Processing: Image Communication</span>, 2021 <br/>
                <a class="btn btn-red" href="https://www.sciencedirect.com/science/article/abs/pii/S0923596521002204">paper</a> / <a class="btn btn-dark" href="https://github.com/peylnog/EnsembleNet">code</a>
            </div>
        </div>

        <!-- SPL 2020 -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/SPL.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">Cumulative rain density sensing network for single image derain</a><br/>
                <span class="bold">Long Peng</span>, Aiwen Jiang, Qiaosi Yi, Mingwen Wang.<br/>
                <span class="italic">IEEE Signal Processing Letters (SPL)</span>, 2020 <br/>
                <a class="btn btn-red" href="https://ieeexplore.ieee.org/abstract/document/9001158">paper</a> / <a class="btn btn-dark" href="https://github.com/peylnog/CRDNet">code</a>
            </div>
        </div>

        <!-- ========== Under Review ========== -->
        <h3 style="margin-top: 32px; margin-bottom: 16px; color: #345; border-bottom: 1px solid #ddd; padding-bottom: 8px;">Under Review / Preprints</h3>

        <!-- Preprint: RobustGS -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/RobustGS.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">RobustGS: Unified Boosting of Feedforward 3D Gaussian Splatting under Low-Quality Conditions</a><br/>
                Anran Wu*, <span class="bold">Long Peng*</span>, Xin Di*, Xueyuan Dai, Chen Wu, Yang Wang, Xueyang Fu, Yang Cao, Zheng-Jun Zha. <span style="color: #666; font-size: 11px;">Project Leader, Co-first Author</span><br/>
                <span class="italic">Under Review</span>, 2025 <br/>
                <a class="btn btn-red" href="https://arxiv.org/abs/2508.03077">paper</a> / <a class="btn btn-dark" href="https://github.com/wuanran678/RobustGS">code</a>
            </div>
        </div>

        <!-- Preprint: S3Mamba -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/S3Mamba.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">S3Mamba: Arbitrary-Scale Super-Resolution via Scaleable State Space Model</a><br/>
                Peizhe Xia*, <span class="bold">Long Peng*</span>, Xin Di, Renjing Pei, Yang Wang, Yang Cao, Zheng-Jun Zha. <span style="color: #666; font-size: 11px;">Project Leader, Co-first Author</span><br/>
                <span class="italic">Under Review</span>, 2024 <br/>
                <a class="btn btn-red" href="https://arxiv.org/abs/2411.11906">paper</a>
            </div>
        </div>

        <!-- Preprint: ERealSR -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/ERealSR.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">Efficient Real-world Image Super-Resolution Via Adaptive Directional Gradient Convolution</a><br/>
                <span class="bold">Long Peng</span>, Yang Cao, Renjing Pei, Wenbo Li, Jiaming Guo, Xueyang Fu, Yang Wang, Zheng-Jun Zha.<br/>
                <span class="italic">Under Review</span>, 2024 <br/>
                <a class="btn btn-red" href="https://arxiv.org/abs/2405.07023">paper</a> / <a class="btn btn-dark" href="https://github.com/peylnog/ERealSR-DGPNet">code</a>
            </div>
        </div>

        <!-- Preprint: UHD RealSR -->
        <div class="publication row clearfix">
            <div class="row-media" style="height: 100px; background-image: url(/images/paper/UHD_RealSR.jpg); background-color: #f0f0f0;"></div>
            <div class="row-text">
                <a class="publication-title bold">Unveiling Hidden Details: A RAW Data-Enhanced Paradigm for Real-World Super-Resolution</a><br/>
                <span class="bold">Long Peng</span>, Wenbo Li, Jiaming Guo, Xin Di, Haoze Sun, Yong Li, Renjing Pei, Yang Wang, Yang Cao, Zheng-Jun Zha.<br/>
                <span class="italic">Under Review</span>, 2024 <br/>
                <a class="btn btn-red" href="https://arxiv.org/abs/2411.10798">paper</a> / <a class="btn btn-dark" href="https://github.com/peylnog/Unveiling-Hidden-Details-A-RAW-Data-Enhanced-RealSR">code</a>
            </div>
        </div>

    </div>

    <!-- Competitions and Awards -->
    <div>
        <h2 class="noselect">Competitions and Awards</h2>
        <ul class="noselect">
            <li style="margin-bottom: 8px;"><span class="bold">Runner-up Winner</span>, Efficient Super-Resolution Challenge, CVPR 2024.</li>
            <li style="margin-bottom: 8px;"><span class="bold">Runner-up Winner</span>, Real-Time Compressed Image Super-Resolution, CVPR 2024.</li>
            <li style="margin-bottom: 8px;"><span class="bold">Runner-up Winner</span>, Light Field Image Super-Resolution Challenge, CVPR 2024.</li>
            <li style="margin-bottom: 8px;"><span class="bold">Runner-up Winner</span>, Low-light RAW Video Denoising Challenge, ICCV 2025.</li>
        </ul>
    </div>

    <!-- Academic Services -->
    <div>
        <h2 class="noselect">Academic Services</h2>
        <div class="noselect">
            <span><strong>Reviewers:</strong> ACM MM 2024-2025, NeurIPS 2024-2025, CVPR 2025-2026, ICLR 2025-2026, ICML 2025, AAAI 2026, WACV 2025-2026, ICCV 2025, IEEE TPAMI</span>
        </div>
    </div>

    <!-- Contact -->
    <div class="noselect">
        <a id="contact"></a>
        <h2>Contact</h2>
        You are very welcome to contact me regarding my research. I typically respond within a few days.<br/>
        I can be contacted directly at <span class="bold">longp2001</span> [at] <span class="bold">mail.ustc.edu.cn</span>.
    </div>
</div>

<div class="footer noselect">
    <div class="footer-content">
        &copy; 2025 Long Peng. Template from <a style="color: white; text-decoration: underline;" href="https://adam-duan.github.io">Zheng-Peng Duan</a>.
    </div>
</div>
